{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Python\n",
    "\n",
    "\n",
    "### Zhentao Shi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speed\n",
    "\n",
    "* Efficient computation in Python.\n",
    "\n",
    "* Python is a high-level language. \n",
    "  * In most cases, vectorization speeds up computation.\n",
    "* Multiple CPUs for parallel execution\n",
    "  * Save time after optimizing the code for speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorization\n",
    "\n",
    "* Mathematical equivalence $\\neq$ computation equivalence\n",
    "\n",
    "* Speed matter in\n",
    "  * Big data\n",
    "  * Simulations\n",
    "  * Hyper parameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* For example, the preferred algorithm in Lin, Shi, Wang and Yan (2022) \n",
    "  * 8 hours on 24 cores = 192 core-hours\n",
    "\n",
    "* Code optimization is essential for such problems.\n",
    "\n",
    "* Optimizing code takes human time.\n",
    "\n",
    "* Tradeoff between human time and computer time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Econometrics Example\n",
    "\n",
    "In OLS regression, under heteroskedasticity\n",
    "$\n",
    "\\sqrt{n}\\left(\\widehat{\\beta}-\\beta_{0}\\right)\\stackrel{d}{\\to}N\\left(0,E\\left[x_{i}x_{i}'\\right]^{-1}\\mathrm{var}\\left(x_{i}e_{i}\\right)E\\left[x_{i}x_{i}'\\right]^{-1}\\right)\n",
    "$\n",
    "where $\\mathrm{var}\\left(x_{i}e_{i}\\right)$ can be estimated by \n",
    "\n",
    "$$\n",
    "\\underset{\\mathrm{opt1}}{\\frac{1}{n}\\sum_{i=1}^{n}x_{i}x_{i}'\\widehat{e}_{i}^{2}}=\\underset{\\mathrm{opt2,3}}{\\frac{1}{n}X'DX}=\\underset{\\mathrm{opt 4}}{\\frac{1}{n}\\left(X'D^{1/2}\\right)\\left(D^{1/2}X\\right)}\n",
    "$$\n",
    "\n",
    "where $D$ is a diagonal matrix of $\\left(\\widehat{e}_{1}^{2},\\widehat{e}_{2,}^{2},\\ldots,\\widehat{e}_{n}^{2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At least 4 mathematically equivalent ways:\n",
    "\n",
    "1. literally sum $\\hat{e}_i^2 x_i x_i'$  over $i=1,\\ldots,n$ one by one.\n",
    "2. $X' \\mathrm{diag}(\\hat{e}^2) X$, with a dense central matrix.\n",
    "3. $X' \\mathrm{diag}(\\hat{e}^2) X$, with a sparse central matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix \n",
    "import random\n",
    "import datetime\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def lpm(n):\n",
    "    # estimation in a linear probability model\n",
    "\n",
    "    # set the parameters\n",
    "    b0 = np.array([-1, 1])\n",
    "\n",
    "    # generate the data\n",
    "    e = np.random.normal(size=n)\n",
    "    X = np.hstack((np.ones((n, 1)), np.random.normal(size=(n, 1))))\n",
    "    Y = (X @ b0 + e >= 0)\n",
    "\n",
    "    # OLS estimation\n",
    "    bhat = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "\n",
    "    # calculate the t-value\n",
    "    bhat2 = bhat[1]  # parameter we want to test\n",
    "    e_hat = Y - X @ bhat\n",
    "    return X, e_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We run the 3 estimators for the same data, and compare the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 10 , Rep = 5000 , opt = 1 ,time = 0.7726907730102539 \n",
      "\n",
      "n = 10 , Rep = 5000 , opt = 2 ,time = 0.5923724174499512 \n",
      "\n",
      "n = 10 , Rep = 5000 , opt = 3 ,time = 1.978090524673462 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "\n",
    "# an example of robust variance matrix.\n",
    "# compare the implementation via matrix and vectorization.\n",
    "\n",
    "# n = 5000; Rep = 10 # large matrix\n",
    "\n",
    "n = 10; Rep = 5000 # small matrix\n",
    "\n",
    "\n",
    "\n",
    "for opt in range(1, 4):\n",
    "    pts0 = time.time()\n",
    "    \n",
    "    # initialize the matrix for computing the variance-covariance matrix\n",
    "    XXe2 = np.zeros((2, 2))\n",
    "\n",
    "    # loop over the replications and compute the variance-covariance matrix\n",
    "    for iter in range(Rep):\n",
    "        np.random.seed(iter)\n",
    "        X, e_hat = lpm(n)\n",
    "        \n",
    "        # compute the variance-covariance matrix using element-by-element calculation\n",
    "        if opt == 1:\n",
    "            for i in range(n):\n",
    "                XXe2 += e_hat[i]**2 * np.matmul( X[i,].T, X[i,] )\n",
    "        \n",
    "        # compute the variance-covariance matrix using matrix multiplication with dense matrices\n",
    "        elif opt == 2:\n",
    "            e_hat2_M = np.zeros((n, n))\n",
    "            np.fill_diagonal(e_hat2_M, e_hat**2)\n",
    "            XXe2 = X.T @ e_hat2_M @ X\n",
    "        \n",
    "        # compute the variance-covariance matrix using matrix multiplication with sparse matrices\n",
    "        elif opt == 3:\n",
    "            e_hat2_M = diags(e_hat**2, format='csr')\n",
    "            # The format='csr' argument specifies that the resulting sparse matrix \n",
    "            # should be in Compressed Sparse Row (CSR)\n",
    "            XXe2 = X.T @ e_hat2_M @ X\n",
    "        \n",
    "\n",
    "    print(\"n =\", n, \", Rep =\", Rep, \", opt =\", opt, \",time =\", time.time() - pts0, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Sparse matrix is useful for big matrix. \n",
    "* If the matrix is small, imposing sparsity does not help with speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loops\n",
    "\n",
    "* Python is efficient at managing the memory.\n",
    "  * Pre-defintion is useful in other languages such as R and Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Empirical coverage probability of a Poisson distribution\n",
    "* Write a DIY `CI` for confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mu = 2 \n",
    "\n",
    "def CI(x):\n",
    "    # x is a numpy array of random variables\n",
    "    n = len(x)\n",
    "    mu = np.mean(x)\n",
    "    sig = np.std(x)\n",
    "    upper = mu + 1.96 / np.sqrt(n) * sig\n",
    "    lower = mu - 1.96 / np.sqrt(n) * sig\n",
    "    return {\"lower\": lower, \"upper\": upper}\n",
    "\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)  # You need to define the CI function in Python\n",
    "    return (bounds['lower'] <= mu) & (mu <= bounds['upper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop without pre-definition takes 1.4155597686767578 seconds\n"
     ]
    }
   ],
   "source": [
    "Rep = 10000 # or whatever value you choose\n",
    "sample_size = 10 # or whatever value you choose\n",
    "mu = 10 # or whatever value you choose\n",
    "\n",
    "np.random.seed(1) # set seed for reproducibility\n",
    "out = [] # initialize out as empty list\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "i = 0\n",
    "while i < Rep:\n",
    "    out.append(capture(i))\n",
    "    i += 1\n",
    "\n",
    "pts1 = time.time() - pts0 # check time elapsed\n",
    "print(\"loop without pre-definition takes\", pts1, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop without pre-definition takes 1.2315785884857178 seconds\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) # set seed for reproducibility\n",
    "out = [False] * Rep # initialize out as empty list\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "for i in range(Rep):\n",
    "    out[i] = capture(i)\n",
    "\n",
    "pts1 = time.time() - pts0 # check time elapsed\n",
    "print(\"loop without pre-definition takes\", pts1, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Computing\n",
    "\n",
    "Parallel computing becomes essential when the data size is beyond the storage of a single computer.\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "The package `multiprocessing` is the choice for parallel computing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: See the py script \n",
    "`parallel.py`.\n",
    "\n",
    "I encounter dead loops when running `multiprocessing` in Jupyter notebook on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we have two CPUs running simultaneously, in theory we can cut the time to a half of that on a single CPU. Is that what happening in practice?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
